command:
  - python
  - scripts/run_constructor.py
  - --model_name_or_path
  - deepvk/bert-base-uncased
  - --train_file
  - data/train/snli/train.csv
  - --validation_file 
  - "data/validation/snli/dev.csv"
  - --test_files 
  - "snli:data/validation/snli/dev.csv,
     ru_wanli:data/validation/ru_wanli/test.csv,
     terra:data/validation/terra/val.csv,
     rumednli:data/validation/rumednli/test.csv,
     fever_translated:data/validation/fever_translated/train.csv,
     ling_translated:data/validation/ling_translated/train.csv,
     mnli:data/validation/mnli/dev.csv,
     rcb:data/validation/rcb/val.csv,
     anli:data/validation/anli/dev.csv,
     wanli_translated:data/validation/wanli_translated/train.csv,
     xnli:data/validation/xnli/test.csv"
  - --metric_name 
  - f1
  - --text_column_delimiter 
  - " "
  - --do_train 
  - True
  - --do_eval 
  - True
  - --max_seq_length 
  - 512
  - --logging_strategy 
  - steps
  - --evaluation_strategy 
  - steps
  - --save_strategy 
  - steps
  - --logging_first_step
  - True
  - --save_total_limit 
  - 3
  - --metric_for_best_model 
  - f1
  - --output_dir 
  - tmp/snli
  - --num_train_epochs
  - 5
  - --load_best_model_at_end
  - True
  - ${args}
method: bayes
metric:
  goal: maximize
  name: eval_f1
parameters:
  per_device_train_batch_size:
    values: [8, 16, 32, 64]
  learning_rate:
    values: [1e-4, 5e-5, 1e-5, 5e-6]
  dropout_rate:
    values: [0.05, 0.1, 0.2]
